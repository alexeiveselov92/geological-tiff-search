#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤ —Å TIFF —Ñ–∞–π–ª–∞–º–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–µ—Å—å pipeline: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ ‚Üí OCR ‚Üí —á–∞–Ω–∫–∏–Ω–≥ ‚Üí embeddings ‚Üí –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
"""

import os
import sys
import time
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append("src")

from archive_processor import ArchiveProcessor

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("archive_processing.log", encoding="utf-8"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


class ArchivePipeline:
    def __init__(self):
        self.archive_processor = ArchiveProcessor()
        self.total_start_time = time.time()

    def step1_extract_archives(self):
        """–®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –∞—Ä—Ö–∏–≤–æ–≤"""
        logger.info("üóÇÔ∏è === –®–ê–ì 1: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –ê–†–•–ò–í–û–í ===")

        start_time = time.time()
        metadata = self.archive_processor.process_all_archives()

        if metadata["total_files"] == 0:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è!")
            return False

        extraction_time = time.time() - start_time

        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {extraction_time:.2f} —Å–µ–∫")
        logger.info(f"üìÅ –ê—Ä—Ö–∏–≤–æ–≤: {metadata['total_archives']}")
        logger.info(f"üìÑ –§–∞–π–ª–æ–≤: {metadata['total_files']}")

        # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
        if metadata["total_files"] > 0:
            avg_time_per_file = extraction_time / metadata["total_files"]
            estimated_1000_files = (avg_time_per_file * 1000) / 60
            logger.info(f"‚è±Ô∏è –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ 1000 —Ñ–∞–π–ª–æ–≤: {estimated_1000_files:.1f} –º–∏–Ω—É—Ç")

        return True

    def step2_ocr_processing(self, batch_size=5):
        """–®–∞–≥ 2: OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        logger.info("üìñ === –®–ê–ì 2: OCR –û–ë–†–ê–ë–û–¢–ö–ê ===")

        start_time = time.time()

        # –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç
        from ocr_processor import process_extracted_files

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è resume
        extracted_text_dir = Path("data/extracted_text")
        existing_files = []
        if extracted_text_dir.exists():
            existing_files = list(extracted_text_dir.glob("*.json"))

        logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(existing_files)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")

        results = process_extracted_files(batch_size=batch_size, resume_from=True)

        ocr_time = time.time() - start_time

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        total_text_files = len(list(extracted_text_dir.glob("*.json"))) if extracted_text_dir.exists() else 0

        if total_text_files == 0:
            logger.error("OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –Ω–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤!")
            return False

        successful = len([r for r in results if r["text_length"] > 0])
        avg_text_length = sum(r["text_length"] for r in results) / len(results) if results else 0

        logger.info(f"‚úÖ OCR –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {ocr_time:.2f} —Å–µ–∫")
        if results:
            logger.info(f"üìù –£—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π: {successful}/{len(results)}")
            logger.info(f"üìä –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {avg_text_length:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        else:
            logger.info(f"üìã –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (resume). –í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {total_text_files}")
            logger.info(f"üìä –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")

        return True

    def step3_text_processing(self):
        """–®–∞–≥ 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤"""
        logger.info("‚úÇÔ∏è === –®–ê–ì 3: –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–ê –ò –ß–ê–ù–ö–ò–ù–ì ===")

        start_time = time.time()

        try:
            # –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç
            from text_processor import process_all_extracted_texts

            results = process_all_extracted_texts()

            if not results:
                logger.error("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
                return False

            processing_time = time.time() - start_time

            total_chunks = sum(len(r.get("chunks", [])) for r in results)
            avg_chunks_per_file = total_chunks / len(results) if results else 0

            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f} —Å–µ–∫")
            logger.info(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")
            logger.info(f"üß© –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
            logger.info(f"üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤ –Ω–∞ —Ñ–∞–π–ª: {avg_chunks_per_file:.1f}")

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return False

    def step4_create_embeddings(self):
        """–®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π"""
        logger.info("üß† === –®–ê–ì 4: –°–û–ó–î–ê–ù–ò–ï EMBEDDINGS ===")

        start_time = time.time()

        try:
            # –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç
            from embeddings_creator import create_embeddings_for_test_data

            total_chunks = create_embeddings_for_test_data()

            if total_chunks == 0:
                logger.error("–°–æ–∑–¥–∞–Ω–∏–µ embeddings –Ω–µ –¥–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
                return False

            embeddings_time = time.time() - start_time

            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ embeddings –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {embeddings_time:.2f} —Å–µ–∫")
            logger.info(f"üß† –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ embeddings: {e}")
            return False

    def step5_build_search_index(self):
        """–®–∞–≥ 5: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"""
        logger.info("üîç === –®–ê–ì 5: –ü–û–°–¢–†–û–ï–ù–ò–ï –ü–û–ò–°–ö–û–í–û–ì–û –ò–ù–î–ï–ö–°–ê ===")

        start_time = time.time()

        try:
            # –õ–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç
            from search_engine import SearchEngine

            search_engine = SearchEngine()
            search_engine.build_index()

            index_time = time.time() - start_time

            logger.info(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω –∑–∞ {index_time:.2f} —Å–µ–∫")

            # –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            test_results = search_engine.search("–≥–µ–æ–ª–æ–≥–∏—è", top_k=3)
            if test_results:
                logger.info(f"üîç –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ —É—Å–ø–µ—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(test_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            else:
                logger.warning("‚ö†Ô∏è –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
            return False

    def run_full_pipeline(self, batch_size=5, skip_steps=None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        skip_steps = skip_steps or []

        logger.info("üöÄ === –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û PIPELINE –û–ë–†–ê–ë–û–¢–ö–ò –ê–†–•–ò–í–û–í ===")
        logger.info(f"‚öôÔ∏è –†–∞–∑–º–µ—Ä batch –¥–ª—è OCR: {batch_size}")

        steps = [
            (1, "extract_archives", self.step1_extract_archives),
            (2, "ocr_processing", lambda: self.step2_ocr_processing(batch_size)),
            (3, "text_processing", self.step3_text_processing),
            (4, "create_embeddings", self.step4_create_embeddings),
            (5, "build_search_index", self.step5_build_search_index),
        ]

        for step_num, step_name, step_func in steps:
            if step_name in skip_steps:
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —à–∞–≥ {step_num}: {step_name}")
                continue

            logger.info(f"\n{'='*60}")

            if not step_func():
                logger.error(f"‚ùå –®–∞–≥ {step_num} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π!")
                return False

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            elapsed = time.time() - self.total_start_time
            logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.2f} —Å–µ–∫")

        total_time = time.time() - self.total_start_time

        logger.info(f"\n{'='*60}")
        logger.info("üéâ === PIPELINE –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û! ===")
        logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫ ({total_time/60:.1f} –º–∏–Ω)")
        logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        logger.info("üìû –ó–∞–ø—É—Å—Ç–∏—Ç–µ ask_geo.py –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∏—Å—Ç–µ–º–æ–π")

        return True


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""

    pipeline = ArchivePipeline()

    if len(sys.argv) == 1:
        # –ë–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ - –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline
        logger.info("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏)")
        success = pipeline.run_full_pipeline()

    elif "--help" in sys.argv or "-h" in sys.argv:
        print("üóÇÔ∏è –û–ë–†–ê–ë–û–¢–ö–ê –ê–†–•–ò–í–û–í - –°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        print()
        print("–ö–æ–º–∞–Ω–¥—ã:")
        print("  python process_archives.py                    - –ü–æ–ª–Ω—ã–π pipeline")
        print("  python process_archives.py --batch 10         - –° —É–∫–∞–∑–∞–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞ batch")
        print("  python process_archives.py --skip ocr         - –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å OCR")
        print("  python process_archives.py --extract-only     - –¢–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ")
        print("  python process_archives.py --ocr-only         - –¢–æ–ª—å–∫–æ OCR")
        print("  python process_archives.py --index-only       - –¢–æ–ª—å–∫–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è")
        print()
        print("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
        print("  --batch N      - –†–∞–∑–º–µ—Ä batch –¥–ª—è OCR (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5)")
        print("  --skip STEP    - –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —à–∞–≥ (extract_archives, ocr_processing, etc.)")
        print()
        return

    elif "--extract-only" in sys.argv:
        logger.info("–ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–æ–≤")
        success = pipeline.step1_extract_archives()

    elif "--ocr-only" in sys.argv:
        batch_size = 5
        if "--batch" in sys.argv:
            try:
                batch_idx = sys.argv.index("--batch")
                batch_size = int(sys.argv[batch_idx + 1])
            except (IndexError, ValueError):
                logger.warning("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä --batch, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5")

        logger.info("–ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        success = pipeline.step2_ocr_processing(batch_size)

    elif "--index-only" in sys.argv:
        logger.info("–ó–∞–ø—É—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞")
        success = pipeline.step5_build_search_index()

    else:
        # –ü–æ–ª–Ω—ã–π pipeline —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        batch_size = 5
        skip_steps = []

        if "--batch" in sys.argv:
            try:
                batch_idx = sys.argv.index("--batch")
                batch_size = int(sys.argv[batch_idx + 1])
            except (IndexError, ValueError):
                logger.warning("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä --batch, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5")

        if "--skip" in sys.argv:
            try:
                skip_idx = sys.argv.index("--skip")
                skip_steps = [sys.argv[skip_idx + 1]]
            except IndexError:
                logger.warning("–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä --skip")

        success = pipeline.run_full_pipeline(batch_size=batch_size, skip_steps=skip_steps)

    if success:
        logger.info("üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        sys.exit(0)
    else:
        logger.error("‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–∞–º–∏!")
        sys.exit(1)


if __name__ == "__main__":
    main()
